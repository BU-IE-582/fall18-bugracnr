---
title: "HW3 Report"
author: "Alim Bugra Cinar"
date: "16 November 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Introduction

  This is my homework report for Homework 3 of IE 582 Statistical Learning for Data Mining class at Bogazici University Industrial Engineering Department. In this project we are given two tasks. In the first task, we are given uWaveGestureLibrary, which is a three-axis accelerometer data collected to characterize eight gesture patterns. Our task is to firstly visualize the gestures and secondly apply nearest-neighbor classifier to classify the test data. 
  In the second task, we will use a penalized regression approach with fused penalties to classify EcG data.
  
# 2. Task 1

## 2.1 Data Loading and Preprocessing

  In this part, I will firstly load the required libraries and data. Then, as we are asked to plot the gestures, I will create a function for this task. The data consists of acceleration information, therefore, we need to convert it to position information first. Then, we need to plot that positions. The function does this task.
  
```{r, include=FALSE, eval=TRUE}
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)

### Data Paths
path_xtest <-    "Files/uWaveGestureLibrary_X_TEST"   
path_xtrain <-   "Files/uWaveGestureLibrary_X_TRAIN"  
path_ytest <-   "Files/uWaveGestureLibrary_Y_TEST"   
path_ytrain <-   "Files/uWaveGestureLibrary_Y_TRAIN" 
path_ztest <-    "Files/uWaveGestureLibrary_Z_TEST"  
path_ztrain <-   "Files/uWaveGestureLibrary_Z_TRAIN" 


### Loading Data
xtest <- read.table(path_xtest)
ytest <- read.table(path_ytest)
ztest <- read.table(path_ztest)
xtrain <- read.table(path_xtrain)
ytrain <- read.table(path_ytrain)
ztrain <- read.table(path_ztrain)


### color and Shape Values
cols <- rep("black",315)
cols[1:25] <- "blue"
cols[290:315] <- "red"
shapes <- rep(1,315)
shapes[1:25] <- 2
shapes[290:315] <- 4


### Function: pathplotter
pathplotter <- function(instanceno)
{
  ax <- unlist(xtrain[instanceno,2:ncol(xtrain)])
  ay <- unlist(ytrain[instanceno,2:ncol(xtrain)])
  az <- unlist(ztrain[instanceno,2:ncol(xtrain)])

  #calculate Velocities
  vx <- cumsum(ax)
  vy <- cumsum(ay)
  vz <- cumsum(az)
  
  #create Position Vectors
  xx <- rep(NA, 315)
  xx[1] <- 0
  xy <- rep(NA, 315)
  xy[1] <- 0
  xz <- rep(NA, 315)
  xz[1] <- 0
  
  #calculate Position Values
  for (i in 2:315) {
    xx[i] <- (vx[i] - vx[i-1])/2
    xy[i] <- (vy[i] - vy[i-1])/2
    xz[i] <- (vz[i] - vz[i-1])/2
  }
  
  xx <- cumsum(xx) + cumsum(vx)
  xy <- cumsum(xy) + cumsum(vy)
  xz <- cumsum(xz) + cumsum(vz)
  
  #Plot
  scatterplot3d(xx,xy,xz, color = cols, pch = shapes, main = paste("Gesture ", xtrain[instanceno,1]))
}
```
  
## 2.2 Task 1.a

In this part, I will plot 8 gestures. The blue triangles show where the movement begins, and the red crosses show where the movement ends.

```{r}
pathplotter(11)
```
```{r}
pathplotter(20)
```

```{r}
pathplotter(13)
```

```{r}
pathplotter(5)
```

```{r}
pathplotter(3)
```

```{r}
pathplotter(1)
```

```{r}
pathplotter(7)
```

```{r}
pathplotter(6)
```

## 2.3 Task 1.b

In this task, I will train 2 NN models, which are using Euclidean and Manhattan distances. Firstly, I will do scale the data, then I will find the optimal k values by using 10-fold cross validation for both of the models. 

I will use knn function from FNN package in the first part as it uses euclidean distances, and in the second part I will use nn2 function from RANN.L1 package as it uses manhattan distances.

```{r,eval=TRUE, include=FALSE}
trainclass <- xtrain[,1]
testclass <- xtest[,1]

colnum <- ncol(xtrain)

testdata <- cbind(xtest[,2:colnum],ytest[,2:colnum],ztest[,2:colnum])
testdata <- scale(testdata)

traindata <- cbind(xtrain[,2:colnum],ytrain[,2:colnum],ztrain[,2:colnum])
traindata <- scale(traindata)

```

```{r, eval=TRUE,include=FALSE}
########## Distance Measure : Euclidean
set.seed(122)
k_levels=c(1:10)
nofReplications=10
nFolds=10
indices=generateCVRuns(trainclass,nofReplications,nFolds,stratified=TRUE)
cvresult=data.table()

cv_euc_time <- system.time(
for(i in 1:nofReplications) {
  thisReplication=indices[[i]]
  for(j in 1:nFolds){
    testindices=thisReplication[[j]]
    
    cvtrain=traindata[-testindices,]        
    cvtest=traindata[testindices,]
    

    for(y in 1:length(k_levels)){
      param_k=k_levels[y]
      predict_knn=knn(cvtrain, cvtest,trainclass[-testindices], k = param_k)
      cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
                                         Predictions=as.numeric(as.character(predict_knn)),Real=trainclass[testindices]))
    }   
  }    
}
)
```

```{r}
comparison <- cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
comparison <- comparison[order(Accu)]
comparison
```

As we can see from the results above, Model using Euclidean Distance best performs with k = 3.

```{r, eval= TRUE, include=FALSE}
###### Distance Measure: Manhattan
cvresult=data.table()

cv_manh_time <- system.time(
for(i in 1:nofReplications) {
    thisReplication=indices[[i]]
  for(j in 1:nFolds){
    testindices=thisReplication[[j]]
    
    cvtrain=traindata[-testindices,]        
    cvtest=traindata[testindices,]
    tclass <- trainclass[-testindices]
    
 
    for(y in 1:length(k_levels)){
      param_k=k_levels[y]
      predict_knn=nn2(cvtrain, cvtest, k = param_k)
      cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
                                         Predictions=tclass[as.vector(predict_knn$nn.idx)],
                                                                Real=trainclass[testindices]))
    
    }   
  }    
}
)
```

```{r}
comparison <- cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
comparison <- comparison[order(Accu)]
comparison
```

As it is shown in the table above, the manhattan distance model best performs with k = 1.

## 2.4 Task 1.c
In this part, I will do evaluate the performance of the models on test data. I will present them in confusion matrices. At last, I will present the runtime records as an additional information.

```{r, eval=TRUE, include = FALSE}
## Euclidean
euc_pred_time <- system.time(predict_knn <- knn(traindata,testdata, trainclass, k=3))
Predictions=as.numeric(as.character(predict_knn))

```

```{r}
euc_comp <- (Predictions==testclass)
table(Predictions,testclass)
accuracy <- sum(euc_comp)/length(testclass)
accuracy
```

As we can see, the euclideanmodel works with 94.3% accuracy which is a very high value. 

```{r, eval=TRUE, include = FALSE}
manh_pred_time <- system.time(predict_knn <- nn2(traindata, testdata, k = 1))
Predictions <- trainclass[as.vector(predict_knn$nn.idx[,1])]
man_comp <- (Predictions==testclass)
```

```{r}
table(Predictions,testclass)
accuracy <- sum(man_comp)/length(testclass)
accuracy

```

The manhattan model's accuracy is even better than the first one. The value is 95.4%.

```{r}
times <- rbind(cv_euc_time,cv_manh_time,euc_pred_time,manh_pred_time)
times[,1:3]
```

The table above shows the runtimes of different parts within Task 1. First row is cross validation time of Euclidean Model, second is cross Validation time of Manhattan Model, third is Prediction time of Euclidean model and the last one is Prediction time of Manhattan model.

# 3. Task 2

In this task, we are asked to create a logistic regression model using fused lasso penalties. In this part, I will firstly load and preprocess the data, then train the model.
In the second part of the task, we will manipulate the data and train another model on the new data.

```{r, eval = TRUE, include=FALSE}
require(penalized)


fname='Files/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]


#read test data
fname='Files/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]


#Scale the data
traindata <- scale(traindata)
testdata <- scale(testdata)

#change -1 values to 0
testclass[testclass < 0] <- 0
trainclass[trainclass < 0] <- 0
```


## 3.1 Task 2.a

Now, I will firstly determine the optimal values of the parameters of ridge and fused lasso penalties by using 10-fold cross validation. Then, I will train my model by using the optimal parameter values.

```{r, eval=TRUE, include=FALSE}
#Determine optimal values for lambda 1 and lambda 2
set.seed(256)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]], minlambda2 = 0.5)

#Train the Model
fused_model <- penalized(trainclass, traindata, lambda1 = l1[[1]],lambda2 = l2[[1]],fusedl = TRUE, model = "logistic")

```

```{r}
print(paste("Lambda1 = ", l1[[1]], "Lambda2 = ", l2[[1]]))
```

```{r, eval=TRUE, include=FALSE}
pred_trainclass <- (predict(fused_model, traindata, trainclass) > 0.5) * 1
```

Results for training data.

```{r}
sum(pred_trainclass==trainclass)
table(trainclass, pred_trainclass )   
```

```{r, eval=TRUE, include = FALSE}
pred_testclass <- (predict(fused_model, testdata, testclass) > 0.5) * 1
```

Results for the test data.

```{r}
sum(pred_testclass == testclass)
table(testclass, pred_testclass)
```


## 3.2 Task 2.b

```{r}
fused_model

c <- coefficients(fused_model, "all")
plot(traindata[1,], type = "l", col = "red", ylim = c(min(traindata[1,], traindata[2,], c), max(traindata[1,], traindata[2,], c)))
points(traindata[2,], type = "l", col = "blue")
points(c, type = "l", col = "green")
```


## 3.3 Task 2.c

In this part, I will firstly calculate the new datasets, then find optimal parameters of the penalties. Finally, I will train the model and present the results.

```{r, eval = TRUE, include = FALSE}
fname='Files/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass_c=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]

#read test data
fname='Files/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass_c=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]

#change -1 values to 0
testclass_c[testclass_c < 0] <- 0
trainclass_c[trainclass_c < 0] <- 0


## create empty matrices
traindata_c <- matrix(0,100,96)
testdata_c <- matrix(0,100,96)

#create new data
for (i in 2:96) {
  traindata_c[,i-1] <-  traindata[,i] - traindata[,i-1]
  testdata_c[,i-1] <-  testdata[,i] - testdata[,i-1]
}


#scale the data
traincdata_c <- scale(traindata_c)
testdata_c <- scale(traindata_c)

#optimize parameters and train the model
set.seed(17)
l1c <- optL1(trainclass_c,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 2)
l2c <- optL2(trainclass_c,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1c[[1]], minlambda2 = 1)
fused_model_c <- penalized(trainclass_c, traindata_c, lambda1 = l1c[[1]],lambda2 = l2c[[1]],fusedl = TRUE, model = "logistic")

#calculate results for training data
pred_trainclass_c <- (predict(fused_model_c, traindata_c, trainclass_c) > 0.5) * 1

#calculate results for test data
pred_testclass_c <- (predict(fused_model_c, testdata_c, testclass_c) > 0.5) * 1

```


The results for the training data are below.
```{r}
sum(pred_trainclass_c == trainclass_c)
table(trainclass_c,pred_trainclass_c)
```


The results for the test data are below.
```{r}
sum(pred_testclass_c == testclass_c)
table(testclass_c, pred_testclass_c) 
```


```{r}
#calculate results for training data
pred_trainclass_c <- (predict(fused_model_c, traindata_c, trainclass_c) > 0.75) * 1

#calculate results for test data
pred_testclass_c <- (predict(fused_model_c, testdata_c, testclass_c) > 0.75) * 1
```

The results for the training data are below.
```{r}
sum(pred_trainclass_c == trainclass_c)
table(trainclass_c,pred_trainclass_c)
```


The results for the test data are below.
```{r}
sum(pred_testclass_c == testclass_c)
table(testclass_c, pred_testclass_c) 
```


## 3.4 Task 2.d

The comparison.

```{r}
fused_model_c

c2 <- coefficients(fused_model_c,"all")
plot(traindata_c[2,], type = "l", col = "blue", ylim = c(min(traindata_c[1,], traindata_c[2,], c2), max(traindata_c[1,], traindata_c[2,], c2)))
points(testdata_c[5,], type = "l", col = "red")
points(c2, type = "l", col = "green")
```


# 4 Conclusion