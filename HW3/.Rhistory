xz <- cumsum(xz) + cumsum(vz)
scatterplot3d(xx,xy,xz, color = cols, pch = shapes)
}
pathplotter(ax,ay,az)
#class 2 instance
xtrain[20,1]
ax <- unlist(xtrain[20,2:ncol(xtrain)])
ay <- unlist(ytrain[20,2:ncol(xtrain)])
az <- unlist(ztrain[20,2:ncol(xtrain)])
pathplotter(ax,ay,az)
ax <- abs(unlist(xtrain[11,2:ncol(xtrain)]))
ax <- abs(unlist(xtrain[11,2:ncol(xtrain)]))
ay <- abs(unlist(ytrain[11,2:ncol(xtrain)]))
az <- abs(unlist(ztrain[11,2:ncol(xtrain)]))
pathplotter(ax,ay,az)
ax <- unlist(xtrain[11,2:ncol(xtrain)])
ay <- unlist(ytrain[11,2:ncol(xtrain)])
az <- unlist(ztrain[11,2:ncol(xtrain)])
pathplotter(ax,ay,az)
ax <- unlist(xtrain[20,2:ncol(xtrain)])
ay <- unlist(ytrain[20,2:ncol(xtrain)])
az <- unlist(ztrain[20,2:ncol(xtrain)])
pathplotter(ax,ay,az)
#class 3 instance
xtrain[4,1]
ax <- unlist(xtrain[4,2:ncol(xtrain)])
ay <- unlist(ytrain[4,2:ncol(xtrain)])
az <- unlist(ztrain[4,2:ncol(xtrain)])
pathplotter(ax,ay,az)
ax <- unlist(xtrain[4,2:ncol(xtrain)])
ay <- unlist(ytrain[4,2:ncol(xtrain)])
az <- unlist(ztrain[4,2:ncol(xtrain)])
pathplotter(ax,ay,az)
xtrain[1:50,1]
#class 3 instance
xtrain[13,1]
ax <- unlist(xtrain[13,2:ncol(xtrain)])
ay <- unlist(ytrain[13,2:ncol(xtrain)])
az <- unlist(ztrain[13,2:ncol(xtrain)])
pathplotter(ax,ay,az)
#class 4 instance
xtrain[5,1]
ax <- unlist(xtrain[5,2:ncol(xtrain)])
ay <- unlist(ytrain[5,2:ncol(xtrain)])
az <- unlist(ztrain[5,2:ncol(xtrain)])
pathplotter(ax,ay,az)
#class 5 instance
xtrain[2,1]
ax <- unlist(xtrain[2,2:ncol(xtrain)])
ay <- unlist(ytrain[2,2:ncol(xtrain)])
az <- unlist(ztrain[2,2:ncol(xtrain)])
pathplotter(ax,ay,az)
xtrain[1:50,1]
#class 5 instance
xtrain[3,1]
ax <- unlist(xtrain[3,2:ncol(xtrain)])
ay <- unlist(ytrain[3,2:ncol(xtrain)])
az <- unlist(ztrain[3,2:ncol(xtrain)])
pathplotter(ax,ay,az)
#class 6 instance
xtrain[1,1]
ax <- unlist(xtrain[1,2:ncol(xtrain)])
ay <- unlist(ytrain[1,2:ncol(xtrain)])
az <- unlist(ztrain[1,2:ncol(xtrain)])
pathplotter(ax,ay,az)
#class 7 instance
xtrain[7,1]
ax <- unlist(xtrain[7,2:ncol(xtrain)])
ay <- unlist(ytrain[7,2:ncol(xtrain)])
az <- unlist(ztrain[7,2:ncol(xtrain)])
pathplotter(ax,ay,az)
xtrain[6,1]
ax <- unlist(xtrain[6,2:ncol(xtrain)])
ay <- unlist(ytrain[6,2:ncol(xtrain)])
az <- unlist(ztrain[6,2:ncol(xtrain)])
pathplotter(ax,ay,az)
ax <- unlist(xtrain[13,2:ncol(xtrain)])
ay <- unlist(ytrain[13,2:ncol(xtrain)])
az <- unlist(ztrain[13,2:ncol(xtrain)])
pathplotter(ax,ay,az)
ax <- unlist(xtrain[5,2:ncol(xtrain)])
ay <- unlist(ytrain[5,2:ncol(xtrain)])
az <- unlist(ztrain[5,2:ncol(xtrain)])
pathplotter(ax,ay,az)
rm(ax,ay,az)
gc()
trainclass <- xtrain[,1]
testclass <- xtest[,1]
colnum <- ncol(xtrain)
testdata <- cbind(xtest[,2:colnum],ytest[,2:colnum],ztest[,2:colnum])
traindata <- cbind(xtrain[,2:colnum],ytrain[,2:colnum],ztrain[,2:colnum])
########## Distance Measure : Euclidean
k_levels=c(1:10)
nofReplications=10
nFolds=10
indices=generateCVRuns(trainclass,nofReplications,nFolds,stratified=TRUE)
indices=generateCVRuns(trainclass,nofReplications,nFolds,stratified=TRUE)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
indices=generateCVRuns(trainclass,nofReplications,nFolds,stratified=TRUE)
cvresult=data.table()
cv_euc_time <- system.time(
for(i in 1:nofReplications) {
thisReplication=indices[[i]]
for(j in 1:nFolds){
testindices=thisReplication[[j]]
cvtrain=traindata[-testindices,]
cvtest=traindata[testindices,]
for(y in 1:length(k_levels)){
param_k=k_levels[y]
predict_knn=knn(cvtrain, cvtest,trainclass[-testindices], k = param_k)
cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
Predictions=as.numeric(as.character(predict_knn)),Real=trainclass[testindices]))
}
}
}
)
cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
###### Distance Measure: Manhattan
cvresult=data.table()
cv_manh_time <- system.time(
for(i in 1:nofReplications) {
thisReplication=indices[[i]]
for(j in 1:nFolds){
testindices=thisReplication[[j]]
cvtrain=traindata[-testindices,]
cvtest=traindata[testindices,]
tclass <- trainclass[-testindices]
for(y in 1:length(k_levels)){
param_k=k_levels[y]
predict_knn=nn2(cvtrain, cvtest, k = param_k)
cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
Predictions=tclass[as.vector(predict_knn$nn.idx)],
Real=trainclass[testindices]))
}
}
}
)
cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
## Euclidean
euc_pred_time <- system.time(predict_knn <- knn(traindata,testdata, trainclass, k=1))
Predictions=as.numeric(as.character(predict_knn))
euc_comp <- (Predictions==testclass)
table(Predictions,testclass)
accuracy <- sum(euc_comp)/length(testclass)
accuracy
## Manhattan
manh_pred_time <- system.time(predict_knn <- nn2(traindata, testdata, k = 1))
Predictions <- trainclass[as.vector(predict_knn$nn.idx[,1])]
man_comp <- (Predictions==testclass)
table(Predictions,testclass)
accuracy <- sum(man_comp)/length(testclass)
accuracy
#### System Times
cv_euc_time
cv_manh_time
euc_pred_time
manh_pred_time
rm(list=ls())
gc()
require(penalized)
knitr::opts_chunk$set(echo = TRUE)
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
### Data Paths
path_xtest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_X_TEST"   )
path_xtrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_X_TRAIN"   )
path_ytest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Y_TEST"   )
path_ytrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Y_TRAIN"   )
path_ztest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Z_TEST"   )
path_ztrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Z_TRAIN"   )
### Loading Data
xtest <- read.table(path_xtest)
ytest <- read.table(path_ytest)
ztest <- read.table(path_ztest)
xtrain <- read.table(path_xtrain)
ytrain <- read.table(path_ytrain)
ztrain <- read.table(path_ztrain)
### Color and Shape Values
cols <- rep("black",315)
cols[1:25] <- "blue"
cols[290:315] <- "red"
shapes <- rep(1,315)
shapes[1:25] <- 2
shapes[290:315] <- 4
### Function: pathplotter
pathplotter <- function(instanceno)
{
ax <- unlist(xtrain[instanceno,2:ncol(xtrain)])
ay <- unlist(ytrain[instanceno,2:ncol(xtrain)])
az <- unlist(ztrain[instanceno,2:ncol(xtrain)])
#Calculate Velocities
vx <- cumsum(ax)
vy <- cumsum(ay)
vz <- cumsum(az)
#Create Position Vectors
xx <- rep(NA, 315)
xx[1] <- 0
xy <- rep(NA, 315)
xy[1] <- 0
xz <- rep(NA, 315)
xz[1] <- 0
#Calculate Position Values
for (i in 2:315) {
xx[i] <- (vx[i] - vx[i-1])/2
xy[i] <- (vy[i] - vy[i-1])/2
xz[i] <- (vz[i] - vz[i-1])/2
}
xx <- cumsum(xx) + cumsum(vx)
xy <- cumsum(xy) + cumsum(vy)
xz <- cumsum(xz) + cumsum(vz)
#Plot
scatterplot3d(xx,xy,xz, color = cols, pch = shapes, main = paste("Gesture ", xtrain[instanceno,1]))
}
knitr::opts_chunk$set(echo = TRUE)
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
### Data Paths
path_xtest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_X_TEST"   )
path_xtrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_X_TRAIN"   )
path_ytest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Y_TEST"   )
path_ytrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Y_TRAIN"   )
path_ztest <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Z_TEST"   )
path_ztrain <- gsub  ( "\\\\",  "/", "C:/IE_582_Rep/fall18-bugracnr/HW3/HW3_Files/uWaveGestureLibrary_Z_TRAIN"   )
### Loading Data
xtest <- read.table(path_xtest)
ytest <- read.table(path_ytest)
ztest <- read.table(path_ztest)
xtrain <- read.table(path_xtrain)
ytrain <- read.table(path_ytrain)
ztrain <- read.table(path_ztrain)
### Color and Shape Values
cols <- rep("black",315)
cols[1:25] <- "blue"
cols[290:315] <- "red"
shapes <- rep(1,315)
shapes[1:25] <- 2
shapes[290:315] <- 4
### Function: pathplotter
pathplotter <- function(instanceno)
{
ax <- unlist(xtrain[instanceno,2:ncol(xtrain)])
ay <- unlist(ytrain[instanceno,2:ncol(xtrain)])
az <- unlist(ztrain[instanceno,2:ncol(xtrain)])
#Calculate Velocities
vx <- cumsum(ax)
vy <- cumsum(ay)
vz <- cumsum(az)
#Create Position Vectors
xx <- rep(NA, 315)
xx[1] <- 0
xy <- rep(NA, 315)
xy[1] <- 0
xz <- rep(NA, 315)
xz[1] <- 0
#Calculate Position Values
for (i in 2:315) {
xx[i] <- (vx[i] - vx[i-1])/2
xy[i] <- (vy[i] - vy[i-1])/2
xz[i] <- (vz[i] - vz[i-1])/2
}
xx <- cumsum(xx) + cumsum(vx)
xy <- cumsum(xy) + cumsum(vy)
xz <- cumsum(xz) + cumsum(vz)
#Plot
scatterplot3d(xx,xy,xz, color = cols, pch = shapes, main = paste("Gesture ", xtrain[instanceno,1]))
}
pathplotter(11)
pathplotter(20)
pathplotter(13)
pathplotter(5)
pathplotter(3)
pathplotter(1)
pathplotter(7)
pathplotter(6)
trainclass <- xtrain[,1]
testclass <- xtest[,1]
colnum <- ncol(xtrain)
testdata <- cbind(xtest[,2:colnum],ytest[,2:colnum],ztest[,2:colnum])
testdata <- scale(testdata)
traindata <- cbind(xtrain[,2:colnum],ytrain[,2:colnum],ztrain[,2:colnum])
traindata <- scale(traindata)
########## Distance Measure : Euclidean
k_levels=c(1:10)
nofReplications=10
nFolds=10
indices=generateCVRuns(trainclass,nofReplications,nFolds,stratified=TRUE)
cvresult=data.table()
cv_euc_time <- system.time(
for(i in 1:nofReplications) {
thisReplication=indices[[i]]
for(j in 1:nFolds){
testindices=thisReplication[[j]]
cvtrain=traindata[-testindices,]
cvtest=traindata[testindices,]
for(y in 1:length(k_levels)){
param_k=k_levels[y]
predict_knn=knn(cvtrain, cvtest,trainclass[-testindices], k = param_k)
cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
Predictions=as.numeric(as.character(predict_knn)),Real=trainclass[testindices]))
}
}
}
)
comparison <- cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
comparison <- comparison[order(Accu)]
comparison
###### Distance Measure: Manhattan
cvresult=data.table()
cv_manh_time <- system.time(
for(i in 1:nofReplications) {
thisReplication=indices[[i]]
for(j in 1:nFolds){
testindices=thisReplication[[j]]
cvtrain=traindata[-testindices,]
cvtest=traindata[testindices,]
tclass <- trainclass[-testindices]
for(y in 1:length(k_levels)){
param_k=k_levels[y]
predict_knn=nn2(cvtrain, cvtest, k = param_k)
cvresult=rbind(cvresult,data.table(Replication=i,Fold=j,Method='knn',Klev=param_k,TestId=testindices,
Predictions=tclass[as.vector(predict_knn$nn.idx)],
Real=trainclass[testindices]))
}
}
}
)
comparison <- cvresult[,list(Accu=mean(Predictions==Real)),by=list(Method,Klev)]
comparison <- comparison[order(Accu)]
comparison
## Euclidean
euc_pred_time <- system.time(predict_knn <- knn(traindata,testdata, trainclass, k=3))
Predictions=as.numeric(as.character(predict_knn))
euc_comp <- (Predictions==testclass)
table(Predictions,testclass)
accuracy <- sum(euc_comp)/length(testclass)
accuracy
manh_pred_time <- system.time(predict_knn <- nn2(traindata, testdata, k = 1))
Predictions <- trainclass[as.vector(predict_knn$nn.idx[,1])]
man_comp <- (Predictions==testclass)
table(Predictions,testclass)
accuracy <- sum(man_comp)/length(testclass)
accuracy
times <- rbind(cv_euc_time,cv_manh_time,euc_pred_time,manh_pred_time)
times[,1:3]
require(penalized)
require(data.table)
fname='C:/R/ECG/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]
tlength=ncol(traindata)
noftimeseries=nrow(traindata)
#read test data
fname='C:/R/ECG/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]
#Scale the data
traindata <- scale(traindata)
testdata <- scale(testdata)
#Change -1 values to 0
testclass[testclass < 0] <- 0
trainclass[trainclass < 0] <- 0
#Determine optimal values for lambda 1 and lambda 2
set.seed(256)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
#Determine optimal values for lambda 1 and lambda 2
set.seed(17)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
#Determine optimal values for lambda 1 and lambda 2
set.seed(17)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
#Determine optimal values for lambda 1 and lambda 2
set.seed(256)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]], minlambda2 = 1)
#Determine optimal values for lambda 1 and lambda 2
set.seed(17)
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]],minlambda2 = 0.5)
#Train the Model
fused_model <- penalized(trainclass, traindata, lambda1 = l1[[1]],lambda2 = l2[[1]],fusedl = TRUE, model = "logistic")
print(paste("Lambda1 = ", l1[[1]], "Lambda2 = ", l2[[1]]))
c <- coefficients(fused_model, "all")
data1 <- cbind(rep(1,100),traindata)
probs1 <- t(c)%*%t(data1)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
table(trainclass, pred1)
data2 <- cbind(rep(1,100),testdata)
probs2 <- t(c)%*%t(data2)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testclass, pred2)
c
plot(traindata[1,], type = "l", col = "red", ylim = c(min(traindata[1,], traindata[2,], c), max(traindata[1,], traindata[2,], c)))
points(traindata[2,], type = "l", col = "blue")
points(c, type = "l", col = "green")
fname='C:/R/ECG/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname)) #load data again as the previous one is scaled
fname='C:/R/ECG/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))
## Create empty matrices
traindata_c <- matrix(0,100,96)
testdata_c <- matrix(0,100,96)
#Create new data
for (i in 2:96) {
traindata_c[,i-1] <-  traindata[,i] - traindata[,i-1]
testdata_c[,i-1] <-  testdata[,i] - testdata[,i-1]
}
#Remove the last columns
traindata_c <- traindata_c[,-96]
testdata_c <- testdata_c[,-96]
#scale the data
traincdata_c <- scale(traindata_c)
testdata_c <- scale(traindata_c)
#optimize parameters and train the model
l1c <- optL1(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic")
l2c <- optL2(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1c[[1]], minlambda2 = 0.5)
fused_modelc <- penalized(trainclass, traindata_c, lambda1 = l1c[[1]],lambda2 = l2c[[1]],fusedl = TRUE, model = "logistic")
#Calculate results for training data
c <- coefficients(fused_modelc, "all")
data1c <- cbind(rep(1,100),traindata_c)
probs1 <- t(c)%*%t(data1c)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
#Calculate results for test data
data2c <- cbind(rep(1,100),testdata_c)
probs2 <- t(c)%*%t(data2c)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(traincomp)
table(trainclass,pred1)
sum(testcomp)
table(testclass, pred2)
c
plot(traindata_c[2,], type = "l", col = "blue", ylim = c(min(traindata[1,], traindata[2,], c), max(traindata[1,], traindata[2,], c)))
points(testdata_c[1,], type = "l", col = "blue")
points(testdata_c[5,], type = "l", col = "red")
points(traindata_c[1,], type = "l", col = "red")
points(c, type = "l")
require(MASS)
set.seed(71)
#generate 100 instances for class 1
mu=c(1,2)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.8
covmat[2,1]=0.8
cl1=mvrnorm(100, mu, covmat)
#generate 100 instances for class 2
mu=c(1,3.3)
covmat=matrix(0,2,2)
diag(covmat)=2
covmat[1,2]=0.7
covmat[2,1]=0.7
cl2=mvrnorm(100, mu, covmat)
# concatenate row-wise (bind rows)
alldata=rbind(cl1,cl2)
# assign classes as 0 and 1)
classinfo=c(rep(0,100),rep(1,100))
# concatenate data column-wise (column bind) to add class information to data
alldata=data.frame(cbind(alldata,classinfo))
# plot data
plot(alldata[,1],alldata[,2],col=(alldata[,3]+1),pch=(alldata[,3]+1),xlab='Dim 1',ylab='Dim 2',main='Decision Boundary')
#assign names to variables
names(alldata)=c("X1","X2","Class")
#fit linear regression model (described by Gaussian, check the help)
linearReg=glm(Class~.,'gaussian',alldata)
#get the decision boundary
decisionThreshold=0.5
slope <- coef(linearReg)[2]/(-coef(linearReg)[3])
intercept <- (coef(linearReg)[1]-decisionThreshold)/(-coef(linearReg)[3])
#draws the line given the intercept (a) and the slope (b)
abline(a=intercept, b=slope,col=4,lty=3,lwd=3)
#fit logistic regression (described by binomial, check the help)
logReg=glm(Class~.,'binomial',alldata)
slope <- coef(logReg)[2]/(-coef(logReg)[3])
intercept <- (coef(logReg)[1])/(-coef(logReg)[3])
abline(a=intercept, b=slope,col=3,lty=5,lwd=3)
legend('topleft',c('Linear Reg.','Logistic Reg.'),col=c(4,3),lty=c(3,5),lwd=c(3,3))
par(mfrow=c(1,2))
#plot fitted values for linear regression
plot(alldata[,3],linearReg$fitted.values,ylab='Fitted',xlab='Actual',main='Linear Regression Actual vs Predicted')
#plot fitted values for logistic regression
plot(alldata[,3],logReg$fitted.values,ylab='Fitted',xlab='Actual',main='Logistic Regression Actual vs Predicted')
logReg$fitted.values
