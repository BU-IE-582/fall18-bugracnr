)
l2
#generating arbitrary lambda2 sequences
l2= runif(10,-1,1)
l2
#generating arbitrary lambda2 sequences
l2= runif(10,0.25,1)
l2
time <- system.time(
for(i in 1:10) {
cvfused <- cvl(trainclass, traindata, lambda1 = 1,lambda2 = l2[i],fusedl = TRUE, model = "logistic", fold = 10 )
c <- coefficients(cvfused$fullfit, "all")
datam <- cbind(rep(1,100),traindata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
pred <- (probabilities>0.5) * 1
traincomp <- (trainclass == pred)
sum(traincomp)
datam <- cbind(rep(1,100),testdata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
testcomp <- (testclass == pred)
sum(testcomp)
lambda_result=rbind(lambda_result,data.table(L1=1,L2=l2[j],TrainAccuracy=sum(traincomp),
TestAccuracy=sum(testcomp)))
}
)
lambda_result=data.table()
time <- system.time(
for(i in 1:10) {
cvfused <- cvl(trainclass, traindata, lambda1 = 1,lambda2 = l2[i],fusedl = TRUE, model = "logistic", fold = 10 )
c <- coefficients(cvfused$fullfit, "all")
datam <- cbind(rep(1,100),traindata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
pred <- (probabilities>0.5) * 1
traincomp <- (trainclass == pred)
sum(traincomp)
datam <- cbind(rep(1,100),testdata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
testcomp <- (testclass == pred)
sum(testcomp)
lambda_result=rbind(lambda_result,data.table(L1=1,L2=l2[j],TrainAccuracy=sum(traincomp),
TestAccuracy=sum(testcomp)))
}
)
lambda_result
?cvl
vignette(penalized)
vignette("penalized")
cvfused <- cvl(trainclass, traindata, lambda1 = 1,lambda2 = l2[i],fusedl = TRUE, model = "logistic", fold = 10 )
cvfused
fitl1 <- profL1(trainclass, traindata, minlambda1 = 0, maxlambda1 = 15, lambda2 = 1, fusedl = TRUE, model = "logistic")
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
l1
as.numeric(l1)
l1[[1]]
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", minlambda2 = 0, maxlambda2 = 20)
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic")
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", maxlambda2 = 2)
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]],   maxlambda2 = 20)
l2 <- optL2(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
cvfused <- cvl(trainclass, traindata, lambda1 = l1[[1]],lambda2 = l2,fusedl = TRUE, model = "logistic", fold = 10 )
cvfused <- cvl(trainclass, traindata, lambda1 = l1[[1]],lambda2 = l2[[1]],fusedl = TRUE, model = "logistic", fold = 10 )
cvfused
c <- coefficients(cvfused$fullfit, "all")
c
datam <- cbind(rep(1,100),traindata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
predictions
cvfused
datam <- cbind(rep(1,100),traindata)
predictions <- t(c)%*%t(datam)
predictions
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
pred <- (probabilities>0.5) * 1
traincomp <- (trainclass == pred)
sum(traincomp)
pred <- (cvfused$predictions>0.5)*1
traincomp <- (trainclass == pred)
sum(traincomp)
datam <- cbind(rep(1,100),testdata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
testcomp <- (testclass == pred)
sum(testcomp)
rm(list=ls())
gc
gc()
X <- matrix(0,70,100)
X
for (i in 1:100){
X[1:70,i] <- rnorm(70,mean=0,sd=0.5)
}
colnames(X) = as.character (1:ncol(X))
rownames(X) = as.character (1:nrow(X))
X
a <- sample(1:ncol(X),50,prob=rep(0.5,length(1:ncol(X))))
for (i in 1:50){
X[30:40,a[i]]<-rnorm(length(30:40),mean = -0.7 ,sd=0.5)
}
X
a
Xbeta <- rnorm(100, mean = 0, sd = 0.5)
Xbeta[a] <- rnorm (length(a) , mean = -0.7 , sd = 0.5)
beta <- numeric(100)
beta
beta [1:length(beta)] <- -1
beta
Xbeta
responsep <- numeric(100)
for(i in 1:100){
coeff <- -beta[i] * Xbeta[i]
responsep[i] <- 1/(1+exp(coeff))
}
responsep
> fit <- penalized(response, X, lambda1 = 2, lambda2=3,fusedl=TRUE)
fit <- penalized(response, X, lambda1 = 2, lambda2=3,fusedl=TRUE)
plot(coefficients(fit,"all")[-1],main = "fused lasso", col="red")
fit <- penalized(response, X, lambda1 = 2, lambda2=3,fusedl=TRUE)
fit <- penalized(responsep, X, lambda1 = 2, lambda2=3,fusedl=TRUE)
fit <- penalized(responsep, t(X), lambda1 = 2, lambda2=3,fusedl=TRUE)
plot(coefficients(fit,"all")[-1],main = "fused lasso", col="red")
plot(coefficients(fit,"all")[-1],main = "fused lasso", col="red", type = "l")
fit
help(cvl)
fit
fit2 <- cvl(responsep, t(X), lambda1 = 2, lambda2=3,fusedl=TRUE, fold = 10)
fit2
fit
fname='C:/R/ECG/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]
print(dim(traindata)) #shows that there 100 series (rows) of length 96 time units (columns)
tlength=ncol(traindata)
noftimeseries=nrow(traindata)
#read test data
fname='C:/R/ECG/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]
testclass[testclass < 0] <- 0
trainclass[trainclass < 0] <- 0
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
cvfused <- cvl(trainclass, traindata, lambda1 = l1[[1]],lambda2 = 1,fusedl = TRUE, model = "logistic", fold = 10 )
c <- coefficients(cvfused$fullfit, "all")
plot(c)
plot(c, type = "l")
points(traindata[1,], type = "l", col = "red")
plot(traindata[1,], type = "l", col = "red")
points(c, type = "l")
datam <- cbind(rep(1,100),traindata)
length(c)
cvfused
c
predictions
datam <- cbind(rep(1,100),traindata)
predictions <- t(c)%*%t(datam)
predictions
predictions <- (1/(1+exp(predictions))
predictions <- (1/(1+exp(predictions)))
predictions <- (1/(1+exp(predictions)))
predictions
cvfused
predictions <- (exp(predictions)/(1+exp(predictions)))
predictions
cvfused
predictions <- (exp(predictions)/(1+exp(predictions))) + (1/(1+exp(predictions)))
predictions
predictions <- (1/(1+exp(predictions)))
predictions
predictions <- (1/(1+exp(predictions)))
predictions <- t(c)%*%t(datam)
probs <- t(c)%*%t(datam)
predictions <- (exp(probs)/(1+exp(probs)))
predictions
cvfused
cvl
cvfused
require(MASS)
set.seed(71)
#generate 100 instances for class 1
mu=c(1,2)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.8
covmat[2,1]=0.8
cl1=mvrnorm(100, mu, covmat)
#generate 100 instances for class 2
mu=c(1,3.3)
covmat=matrix(0,2,2)
diag(covmat)=2
covmat[1,2]=0.7
covmat[2,1]=0.7
cl2=mvrnorm(100, mu, covmat)
# concatenate row-wise (bind rows)
alldata=rbind(cl1,cl2)
# assign classes as 0 and 1)
classinfo=c(rep(0,100),rep(1,100))
# concatenate data column-wise (column bind) to add class information to data
alldata=data.frame(cbind(alldata,classinfo))
# plot data
plot(alldata[,1],alldata[,2],col=(alldata[,3]+1),pch=(alldata[,3]+1),xlab='Dim 1',ylab='Dim 2',main='Decision Boundary')
#assign names to variables
names(alldata)=c("X1","X2","Class")
#fit linear regression model (described by Gaussian, check the help)
linearReg=glm(Class~.,'gaussian',alldata)
#get the decision boundary
decisionThreshold=0.5
slope <- coef(linearReg)[2]/(-coef(linearReg)[3])
intercept <- (coef(linearReg)[1]-decisionThreshold)/(-coef(linearReg)[3])
#draws the line given the intercept (a) and the slope (b)
abline(a=intercept, b=slope,col=4,lty=3,lwd=3)
#fit logistic regression (described by binomial, check the help)
logReg=glm(Class~.,'binomial',alldata)
slope <- coef(logReg)[2]/(-coef(logReg)[3])
intercept <- (coef(logReg)[1])/(-coef(logReg)[3])
abline(a=intercept, b=slope,col=3,lty=5,lwd=3)
legend('topleft',c('Linear Reg.','Logistic Reg.'),col=c(4,3),lty=c(3,5),lwd=c(3,3))
par(mfrow=c(1,2))
#plot fitted values for linear regression
plot(alldata[,3],linearReg$fitted.values,ylab='Fitted',xlab='Actual',main='Linear Regression Actual vs Predicted')
#plot fitted values for logistic regression
plot(alldata[,3],logReg$fitted.values,ylab='Fitted',xlab='Actual',main='Logistic Regression Actual vs Predicted')
#A nonlinear case
mu=c(4,4)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.1
covmat[2,1]=0.1
cl1=mvrnorm(50, mu, covmat)
mu=c(0,0)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.1
covmat[2,1]=0.1
cl2=mvrnorm(50, mu, covmat)
mu=c(0,4)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.1
covmat[2,1]=0.1
cl3=mvrnorm(50, mu, covmat)
mu=c(4,0)
covmat=matrix(0,2,2)
diag(covmat)=1
covmat[1,2]=0.1
covmat[2,1]=0.1
cl4=mvrnorm(50, mu, covmat)
alldata=rbind(cl1,cl2,cl3,cl4)
classinfo=c(rep(0,100),rep(1,100))
alldata=data.frame(cbind(alldata,classinfo))
plot(alldata[,1],alldata[,2],col=(alldata[,3]+1),pch=(alldata[,3]+1),xlab='Dim 1',ylab='Dim 2',main='A nonlinear case')
names(alldata)=c("X1","X2","Class")
linearReg=glm(Class~.,'gaussian',alldata)
decisionThreshold=0.5
slope <- coef(linearReg)[2]/(-coef(linearReg)[3])
intercept <- (decisionThreshold-coef(linearReg)[1])/(coef(linearReg)[3])
#draws the line given the intercept (a) and the slope (b)
abline(a=intercept, b=slope,col=4,lty=3,lwd=3)
logReg=glm(Class~.,'binomial',alldata)
slope <- coef(logReg)[2]/(-coef(logReg)[3])
intercept <- (coef(logReg)[1])/(-coef(logReg)[3])
abline(a=intercept, b=slope,col=3,lty=5,lwd=3)
legend('topleft',c('Linear Reg.','Logistic Reg.'),col=c(4,3),lty=c(3,5),lwd=c(3,3))
logReg
plot(alldata[,1],alldata[,2],col=(alldata[,3]+1),pch=(alldata[,3]+1),xlab='Dim 1',ylab='Dim 2',main='A nonlinear case')
par(mfrow = c(1,1))
plot(alldata[,1],alldata[,2],col=(alldata[,3]+1),pch=(alldata[,3]+1),xlab='Dim 1',ylab='Dim 2',main='A nonlinear case')
#draws the line given the intercept (a) and the slope (b)
abline(a=intercept, b=slope,col=4,lty=3,lwd=3)
abline(a=intercept, b=slope,col=3,lty=5,lwd=3)
cvfused
pred <- (cvfused$predictions>0.5)*1
traincomp <- (trainclass == pred)
sum(traincomp)
datam <- cbind(rep(1,100),testdata)
predictions <- t(c)%*%t(datam)
predictions <- exp(predictions)
probabilities <- 1-(1/(1+predictions))
testcomp <- (testclass == pred)
sum(testcomp)
pred <- (probabilities>0.5) * 1
testcomp <- (testclass == pred)
sum(testcomp)
datam <- cbind(rep(1,100),traindata)
probs <- t(c)%*%t(datam)
predictions <- (exp(probs)/(1+exp(probs)))
pred <- (predictions>0.5) * 1
traincomp <- (trainclass == pred)
sum(traincomp)
datam <- cbind(rep(1,100),testdata)
probs <- t(c)%*%t(datam)
datam <- cbind(rep(1,100),testdata)
probs <- t(c)%*%t(datam)
predictions <- (exp(probs)/(1+exp(probs)))
pred <- (predictions>0.5) * 1
testcomp <- (testclass == pred)
sum(testcomp)
data1 <- cbind(rep(1,100),traindata)
probs1 <- t(c)%*%t(data1)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
data2 <- cbind(rep(1,100),testdata)
probs2 <- t(c)%*%t(data2)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)
sum(testcomp)
trainclass
table(testcomp, testclass)
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testcomp, testclass)
table(pred2, testclass)
table(testcomp)
#### Answer 3
traindata
traindata_c <- matrix(0,100,70)
traindata_c
dim(traindata)
traindata_c <- matrix(0,100,96)
traindata_c
testdata_c <- matrix(0,100,96)
for (i in 2:96) {
traindata_c[,i-1] <-  traindata[,i+1] - traindata[,i]
testdata_c[,i-1] <-  testdata[,i+1] - testdata[,i]
}
for (i in 2:96) {
traindata_c[,i-1] <-  traindata[,i] - traindata[,i-1]
testdata_c[,i-1] <-  testdata[,i] - testdata[,i-1]
}
testdata_c
testdata
testdata_c
testdata_c[,96] <- NULL
testdata_c[,96]
testdata_c[,96] <- rep(NULL,100)
rm(list=ls())
require(penalized)
require(data.table)
fname='C:/R/ECG/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]
print(dim(traindata)) #shows that there 100 series (rows) of length 96 time units (columns)
tlength=ncol(traindata)
noftimeseries=nrow(traindata)
#read test data
fname='C:/R/ECG/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]
testclass[testclass < 0] <- 0
trainclass[trainclass < 0] <- 0
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
cvfused <- cvl(trainclass, traindata, lambda1 = l1[[1]],lambda2 = 1,fusedl = TRUE, model = "logistic", fold = 10 )
##### Answer 1
data1 <- cbind(rep(1,100),traindata)
probs1 <- t(c)%*%t(data1)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
data2 <- cbind(rep(1,100),testdata)
probs2 <- t(c)%*%t(data2)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testclass, pred2)
##### Answer 2
c <- coefficients(cvfused$fullfit, "all")
plot(traindata[1,], type = "l", col = "red")
points(traindata[2,], type = "l", col = "blue")
points(c, type = "l")
#### Answer 3
traindata
traindata_c <- matrix(0,100,96)
testdata_c <- matrix(0,100,96)
for (i in 2:96) {
traindata_c[,i-1] <-  traindata[,i] - traindata[,i-1]
testdata_c[,i-1] <-  testdata[,i] - testdata[,i-1]
}
l1 <- optL1(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
#l2 <- optL2(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
cvfused2 <- cvl(trainclass, traindata_c, lambda1 = l1[[1]],lambda2 = 1,fusedl = TRUE, model = "logistic", fold = 10 )
data1c <- cbind(rep(1,100),traindata_c)
probs1 <- t(c)%*%t(data1c)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
data2c <- cbind(rep(1,100),testdata_c)
probs2 <- t(c)%*%t(data2c)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testclass, pred2)
##### Answer 4
c <- coefficients(cvfused2$fullfit, "all")
plot(traindata_c[1,], type = "l", col = "red")
points(traindata_c[2,], type = "l", col = "blue")
points(c, type = "l")
traindata_c <- traindata_c[,-96]
testdata_c <- testdata_c[,-96]
testdata_c
rm(list=ls())
gc()
fname='C:/R/ECG/ecgTRAIN' # data path
traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
trainclass=traindata[,1] # takes -1 and 1
#drop first column
traindata=traindata[,2:ncol(traindata)]
print(dim(traindata)) #shows that there 100 series (rows) of length 96 time units (columns)
tlength=ncol(traindata)
noftimeseries=nrow(traindata)
#read test data
fname='C:/R/ECG/ecgTEST' # data path
testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata
#first column is the class variable
testclass=testdata[,1] # takes -1 and 1
#drop first column
testdata=testdata[,2:ncol(testdata)]
testclass[testclass < 0] <- 0
trainclass[trainclass < 0] <- 0
l1 <- optL1(trainclass,traindata,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
cvfused <- cvl(trainclass, traindata, lambda1 = l1[[1]],lambda2 = 1,fusedl = TRUE, model = "logistic", fold = 10 )
##### Answer 1
c <- coefficients(cvfused$fullfit, "all")
data1 <- cbind(rep(1,100),traindata)
probs1 <- t(c)%*%t(data1)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
data2 <- cbind(rep(1,100),testdata)
probs2 <- t(c)%*%t(data2)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testclass, pred2)
plot(traindata[1,], type = "l", col = "red")
points(traindata[2,], type = "l", col = "blue")
points(c, type = "l")
#### Answer 3
traindata
traindata_c <- matrix(0,100,96)
testdata_c <- matrix(0,100,96)
for (i in 2:96) {
traindata_c[,i-1] <-  traindata[,i] - traindata[,i-1]
testdata_c[,i-1] <-  testdata[,i] - testdata[,i-1]
}
traindata_c <- traindata_c[,-96]
testdata_c <- testdata_c[,-96]
l1 <- optL1(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", minlambda1 = 0, maxlambda1 = 20)
#l2 <- optL2(trainclass,traindata_c,fusedl = TRUE, fold = 10, model = "logistic", lambda1 = l1[[1]])
cvfused2 <- cvl(trainclass, traindata_c, lambda1 = l1[[1]],lambda2 = 1,fusedl = TRUE, model = "logistic", fold = 10 )
c <- coefficients(cvfused2$fullfit, "all")
data1c <- cbind(rep(1,100),traindata_c)
probs1 <- t(c)%*%t(data1c)
predictions1 <- (exp(probs1)/(1+exp(probs1)))
pred1 <- (predictions1>0.5) * 1
traincomp <- (trainclass == pred1)
sum(traincomp)
data2c <- cbind(rep(1,100),testdata_c)
probs2 <- t(c)%*%t(data2c)
predictions2 <- (exp(probs2)/(1+exp(probs2)))
pred2 <- (predictions2>0.5) * 1
testcomp <- (testclass == pred2)*1
sum(testcomp)
table(testclass, pred2)
##### Answer 4
c <- coefficients(cvfused2$fullfit, "all")
plot(traindata_c[1,], type = "l", col = "red")
points(traindata_c[2,], type = "l", col = "blue")
points(c, type = "l")
testclass
plot(traindata_c[2,], type = "l", col = "blue")
trainclass[2]
testclass[5]
testclass[1]
testclass[1]
plot(traindata_c[2,], type = "l", col = "blue")
points(testdata_c[1,], type = "l", col = "blue")
points(testdata_c[5,], type = "l", col = "red")
points(traindata_c[1,], type = "l", col = "red")
points(c, type = "l")
testclass
