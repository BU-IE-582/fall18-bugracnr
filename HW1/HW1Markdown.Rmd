---
title: "Homework 1 Report"
author: "Alim Buðra Çýnar - IE 582 - Fall 2018"
date: "18 October 2018"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1. Introduction

In this project, we are given Premier League match scores and odds generated by several bookmakers for those matches from 2010 to present. The analysis required is to find out whether the bookmakers are good at determining probabilities of over and under. To determine this information, the main idea is to generate probability ranges and average probabilities determined by the bookmakers in those ranges. Then, comparing the average probabilities with empirical probabilities which is the ratio of the match finished over in a range to number of all matches in respective ranges will give us an idea of whether the bookmaker is good at determining probabilities.

Another task is to see whether a bookmaker is consistently good at determining probabilities. To find out, the information above is simply generated for every available year and compared. 

The last task is to find out some information about the nature of change in the odds. Change in the odds is interesting as the bookmakers can change their odds with events such as injuries, news about the teams etc. I made several analysis on the change in the odds. Firstly, I wanted to see the nature of the number of changes. Therefore, I generated the data of how many changes per match is done by the bookmakers. Then, I wanted to see the dynamics of the average number of changes over time. In addition, I compared the distributions of initial and final odds to see if there is anything remarkable.

# 2. Data Preprocessing
## 2.1 Packages & Data

data.table & anytime packages are used in the data. matches and odds datasets are the main datasets used in the analysis.

```{r}
require(data.table)
require(anytime)

#save paths
matches_file_path = "HW1_Files/df9b1196-e3cf-4cc7-9159-f236fe738215_matches.rds"
odd_details_file_path = "HW1_Files/df9b1196-e3cf-4cc7-9159-f236fe738215_odd_details.rds"

#load data
matches=readRDS(matches_file_path)
odds=readRDS(odd_details_file_path)
```

## 2.2 Processing Matches Data

Original matches data consists of leagueId, matchId, home, away, score, date and type information. I need to firstly convert date data, then, seperate score data. Additionally, I will create information of is the match ended over, 1, x, and 2. One last thing is to keeping only the complete data, then removing the unnecessary information.

```{r}
#keep only unique matches
matches=unique(matches)

#keep year data
matches[,match_time:=anytime(date)]
matches[,Year:=year(match_time)]
matches[,c("match_time","date","leagueId","type"):=NULL]

#Over Under & 1x2 Results
matches[,c("HomeGoals","AwayGoals"):=tstrsplit(score,':')]
matches$HomeGoals=as.numeric(matches$HomeGoals)
matches[,AwayGoals:=as.numeric(AwayGoals)]
matches[,TotalGoals:=HomeGoals+AwayGoals]
matches[,IsOver:=0]
matches[TotalGoals>2,IsOver:=1]
matches[,Is1 := HomeGoals > AwayGoals]
matches[,Is2 := HomeGoals < AwayGoals]
matches[,IsX := HomeGoals == AwayGoals]

#Keep only complete data
matches=matches[complete.cases(matches)]

#delete unnecessary
matches[,c("HomeGoals","AwayGoals","TotalGoals") := NULL]
```

# 3. Task 1.a & 1.b
In this task we will compare empirical over probabilites with the average over probabilities generated by the bookmakers.

## 3.1 Preprocessing of Odds data

I need only "ou" type of bets with 2.5 total handicap. Firstly, I will generate that data. Then, I need initial and final odds for comparison. Therefore, they will be seperated. One last thing needed is the probabilities, thus, they will be introduced in the respective datasets.

```{r}

#keep only over & under matches with 2.5 handicap
odds_ov_un=odds[betType=='ou' & totalhandicap=='2.5']



#order data in ascending date & find initial and final matches
odds_ov_un=odds_ov_un[order(matchId, oddtype,bookmaker,date)]

odds_ov_un_initial=odds_ov_un[,list(start_odd=odd[1]),
                              by=list(matchId,oddtype,bookmaker)]

odds_ov_un_final=odds_ov_un[,list(final_odd=odd[.N]),
                            by=list(matchId,oddtype,bookmaker)]
```


We also need cutpoints throughout our analysis. They need to be introduced.

```{r}
#introduce cutpoints to be analyzed
cutpoints=seq(0,1,0.05)
```

Processing of initial data is done by firstly reformatting data to be in the wide format. Then, match probabilities are created. 

```{r}

#Probabilities for initial data
wide_ov_un_initial <- dcast(odds_ov_un_initial,
                              matchId + bookmaker ~oddtype,
                              value.var="start_odd")


initial_merged_data <- merge(matches[,c("matchId", "IsOver","Year")],wide_ov_un_initial,by='matchId')
initial_merged_data[,probOver:=1/over]
initial_merged_data[,probUnder:=1/under]
initial_merged_data[,totalProb:=probOver+probUnder]
initial_merged_data[,probOver:=probOver/totalProb]
initial_merged_data[,probUnder:=probUnder/totalProb]
initial_merged_data=initial_merged_data[complete.cases(initial_merged_data)]
initial_merged_data[,totalProb:=NULL]
initial_merged_data[,odd_cut_over:=cut(probOver,cutpoints)]
```


Processing of the final data is done in the same way with the initial data.

```{r}
#Probabilites for the final data
wide_ov_un_final <- dcast(odds_ov_un_final,
                     matchId + bookmaker ~oddtype,
                     value.var="final_odd")

  final_merged_data <- merge(matches[,c("matchId", "IsOver","Year")],wide_ov_un_final,by='matchId')
  final_merged_data[,probOver:=1/over]
  final_merged_data[,probUnder:=1/under]
  final_merged_data[,totalProb:=probOver+probUnder]
  final_merged_data[,probOver:=probOver/totalProb]
  final_merged_data[,probUnder:=probUnder/totalProb]
  final_merged_data=final_merged_data[complete.cases(final_merged_data)]
  final_merged_data[,totalProb:=NULL]
  final_merged_data[,odd_cut_over:=cut(probOver,cutpoints)]
```

## 3.2 Analysis of Pinnacle

### 3.2.1 Task 1.a
First bookmaker is chosen as Pinnacle. Firstly, pinnacle's data will be filtered, then, the empirical and average probabilities will be creted. Lastly, the plots will be created. 

```{r}
pinnacle_initial <- initial_merged_data[bookmaker == "Pinnacle"]
pinnacle_final <- final_merged_data[bookmaker == "Pinnacle"]


pinnacle_initial_summary=pinnacle_initial[,list(empirical_over=mean(IsOver),
                                   probabilistic_over=mean(probOver),.N),
                             by=list(odd_cut_over)]


pinnacle_final_summary=pinnacle_final[,list(empirical_over=mean(IsOver),
                                            probabilistic_over=mean(probOver),.N),
                                      by=list(odd_cut_over)]
par(bg="gray")

#Task 1.a
plot(pinnacle_initial_summary[,list(empirical_over,probabilistic_over)],cex=1, col = "blue", pch = 2, xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Probabilities")
points(pinnacle_final_summary[,list(empirical_over,probabilistic_over)],cex=1, col = "red", pch = 5)
abline(0,1,col='green')
```

Blue triangles and red diamonds are showing the initial and final data respectively. Green line is the x=y line, and we expect a good bookmaker creates probabilites around that line. As we can see from the graph, Pinnacle does a pretty good work on the probabilites between 0.4 and 0.65 for both initial and final data. As the rest does not have large number of samples, they may not be concerning issue. Another observation is there is no significant improvements between initial and final data. Even some initial data is closr to the line than final data.

### 3.2.2 Task 1.b Preprocessing

Firstly, necessary data must be generated.

```{r}
pinnacle_final_yearly_analysis=pinnacle_final[,list(empirical_over=mean(IsOver),
                                                    probabilistic_over=mean(probOver),.N),
                                              by=list(Year,odd_cut_over)]

pinnacle_final_yearly_analysis=pinnacle_final_yearly_analysis[order(Year)]


pinnacle_initial_yearly_analysis=pinnacle_initial[,list(empirical_over=mean(IsOver),
                                   probabilistic_over=mean(probOver),.N),
                             by=list(Year,odd_cut_over)]

pinnacle_initial_yearly_analysis=pinnacle_initial_yearly_analysis[order(Year)]
```

I created two functions for visualization as I will use them for the next bookmakers. The functions are plotYears and plotSeries functions. They will get initial and final data as well as minimum and maximum probabilities as inputs. They will return two different plots.

#### 3.2.2.1 plotYears function

```{r}
plotYears <- function(initial_data, final_data, minprob, maxprob)
{
  probCut <- paste("(", minprob, ",", maxprob, "]", sep = "")
  minY <- min(initial_data[odd_cut_over == probCut,list(probabilistic_over)],final_data[odd_cut_over == probCut,list(probabilistic_over)])
  maxY <- max(initial_data[odd_cut_over == probCut,list(probabilistic_over)],final_data[odd_cut_over == probCut,list(probabilistic_over)])
  minX <- min(initial_data[odd_cut_over == probCut,list(empirical_over)],final_data[odd_cut_over == probCut,list(empirical_over)])
  maxX <- 0.1 + max(initial_data[odd_cut_over == probCut,list(empirical_over)],final_data[odd_cut_over == probCut,list(empirical_over)])

  plot(initial_data[odd_cut_over == probCut,list(empirical_over,probabilistic_over)], ylim = c(minY, maxY), xlim = c(minX, maxX),cex=2, pch = 2, 
       xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Values by Years", col= initial_data[odd_cut_over == probCut]$Year - 2010)
  points(final_data[odd_cut_over == probCut,list(empirical_over,probabilistic_over)],cex=2, pch = 5, col= final_data[odd_cut_over == probCut]$Year - 2010)
  abline(0,1,col='red')
  abline(v = minprob)
  abline(v = maxprob)
  legend("topright",cex = 0.55, legend = initial_data[odd_cut_over == probCut]$Year, 
       fill = initial_data[odd_cut_over == probCut]$Year - 2010)
}
```


#### 3.2.2.2 plotSears function


```{r}
plotSeries <- function(initial_data, final_data, minprob, maxprob)
{
  probCut <- paste("(", minprob, ",", maxprob, "]", sep = "")
  minVal <- min(initial_data[odd_cut_over == probCut,list(empirical_over)],
                final_data[odd_cut_over == probCut,list(empirical_over)])
  maxVal <- max(initial_data[odd_cut_over == probCut,list(empirical_over)],
                final_data[odd_cut_over == probCut,list(empirical_over)])
  plot(initial_data[odd_cut_over == probCut,list(Year,empirical_over)], ylab = "Empirical Over", main = "Change in Probabilities Over Time",
       ylim = c(minVal,maxVal), cex=2, pch = 1, col= initial_data[odd_cut_over == probCut]$Year - 2010)
  points(final_data[odd_cut_over == probCut,list(Year,empirical_over)],
         cex=2, pch = 2, col= initial_data[odd_cut_over == probCut]$Year - 2010)
  lines(initial_data[odd_cut_over == probCut,list(Year,empirical_over)], col = "blue")
  lines(final_data[odd_cut_over == probCut,list(Year,empirical_over)], col = "red")
  abline(h = minprob, col = "black")
  abline(h = maxprob, col = "black")
}

```

### 3.2.3 Task 1.b Results

```{r}
par(bg="gray")
plotYears(pinnacle_initial_yearly_analysis,pinnacle_final_yearly_analysis,0.5,0.55)
```

In this plot we observe the initial and final empirical and probabilistic data for each year. Years are colored seperately according to the legend. Triangles and diamonds shows initial and final data respectively. Black vertical lines are showing the chosen probailites and the red line shows the x=y line. As we can see from the graph, the data is distributed almost randomly, no relationships observed between years and initial and final data.

```{r}
par(bg="gray")
plotSeries(pinnacle_initial_yearly_analysis,pinnacle_final_yearly_analysis,0.5,0.55)
```

In this graph, the blue line shows the change in empirical data generated according to initial probabilities, and the red shows the empirical data of final probailities. As we can see, there is no significant improvement over years. Even, the probabilites gets larger then expected in the years 2017 and 2018. Another thing to observe is Pinnacle's initial odds performs better than final ones as more of the initial data is between the determined probability ranges.

## 3.3 Analysis of Betsafe
### 3.3.1 Task 1.a

```{r}
betsafe_initial <- initial_merged_data[bookmaker == "Betsafe"]
betsafe_final <- final_merged_data[bookmaker == "Betsafe"]


betsafe_initial_summary=betsafe_initial[,list(empirical_over=mean(IsOver),
                                                probabilistic_over=mean(probOver),.N),
                                          by=list(odd_cut_over)]


betsafe_final_summary=betsafe_final[,list(empirical_over=mean(IsOver),
                                            probabilistic_over=mean(probOver),.N),
                                      by=list(odd_cut_over)]

par(bg="gray")
plot(betsafe_initial_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "blue", pch = 2,xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Probabilities")
points(betsafe_final_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "red", pch = 5)
abline(0,1,col='green')
```

As we can see, Betsafe's odds perform very good as well, except large probabilities. We can discard them as the number of samples are very low. Another fact to observe is there is no significant improvement seen in the final odds.

### 3.3.2 Task 1.b

```{r}
betsafe_final_yearly_analysis=betsafe_final[,list(empirical_over=mean(IsOver),
                                                    probabilistic_over=mean(probOver),.N),
                                              by=list(Year,odd_cut_over)]

betsafe_final_yearly_analysis=betsafe_final_yearly_analysis[order(Year)]


betsafe_initial_yearly_analysis=betsafe_initial[,list(empirical_over=mean(IsOver),
                                                        probabilistic_over=mean(probOver),.N),
                                                  by=list(Year,odd_cut_over)]

betsafe_initial_yearly_analysis=betsafe_initial_yearly_analysis[order(Year)]

par(bg="gray")
plotYears(betsafe_initial_yearly_analysis,betsafe_final_yearly_analysis,0.5,0.55)
plotSeries(betsafe_initial_yearly_analysis,betsafe_final_yearly_analysis,0.5,0.55)
```

There is no significant improvements observed in both graphs. The variance seems random.

## 3.3 Analysis of Sportingbet
### 3.3.1 Task 1.a

```{r}
sportingbet_initial <- initial_merged_data[bookmaker == "Sportingbet"]
sportingbet_final <- final_merged_data[bookmaker == "Sportingbet"]


sportingbet_initial_summary=sportingbet_initial[,list(empirical_over=mean(IsOver),
                                              probabilistic_over=mean(probOver),.N),
                                        by=list(odd_cut_over)]


sportingbet_final_summary=sportingbet_final[,list(empirical_over=mean(IsOver),
                                          probabilistic_over=mean(probOver),.N),
                                    by=list(odd_cut_over)]

par(bg="gray")
plot(sportingbet_initial_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "blue", pch = 2, xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Probabilities")
points(sportingbet_final_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "red", pch = 5)
abline(0,1,col='green')
```

Sportingbet's probabilites are also good. They seen to be very close to x=y line.

### 3.3.2 Task 1.b

```{r}

sportingbet_final_yearly_analysis=sportingbet_final[,list(empirical_over=mean(IsOver),
                                                  probabilistic_over=mean(probOver),.N),
                                            by=list(Year,odd_cut_over)]

sportingbet_final_yearly_analysis=sportingbet_final_yearly_analysis[order(Year)]


sportingbet_initial_yearly_analysis=sportingbet_initial[,list(empirical_over=mean(IsOver),
                                                      probabilistic_over=mean(probOver),.N),
                                                by=list(Year,odd_cut_over)]

sportingbet_initial_yearly_analysis=sportingbet_initial_yearly_analysis[order(Year)]

par(bg="gray")
plotYears(sportingbet_initial_yearly_analysis,sportingbet_final_yearly_analysis,0.5,0.55)
plotSeries(sportingbet_initial_yearly_analysis,sportingbet_final_yearly_analysis,0.5,0.55)
```

Sportinbet's data shows no relationship between initial and final data, and the improvements over time. They seem to be very random.

## 3.5 Analysis of Tipico
### 3.5.1 Task 1.a
```{r}
tipico_initial <- initial_merged_data[bookmaker == "Tipico"]
tipico_final <- final_merged_data[bookmaker == "Tipico"]


tipico_initial_summary=tipico_initial[,list(empirical_over=mean(IsOver),
                                                      probabilistic_over=mean(probOver),.N),
                                                by=list(odd_cut_over)]


tipico_final_summary=tipico_final[,list(empirical_over=mean(IsOver),
                                                  probabilistic_over=mean(probOver),.N),
                                            by=list(odd_cut_over)]

par(bg="gray")
plot(tipico_initial_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "blue", pch = 2, xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Probabilities")
points(tipico_final_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "red", pch = 5)
abline(0,1,col='green')
```

Tipico's probabilites are also very good, and very close to the line. Again, there is no relationships observed between initial and final probabilities.

### 3.5.2 Task 1.b
```{r}
tipico_final_yearly_analysis=tipico_final[,list(empirical_over=mean(IsOver),
                                                          probabilistic_over=mean(probOver),.N),
                                                    by=list(Year,odd_cut_over)]

tipico_final_yearly_analysis=tipico_final_yearly_analysis[order(Year)]


tipico_initial_yearly_analysis=tipico_initial[,list(empirical_over=mean(IsOver),
                                                              probabilistic_over=mean(probOver),.N),
                                                        by=list(Year,odd_cut_over)]

tipico_initial_yearly_analysis=tipico_initial_yearly_analysis[order(Year)]

par(bg="gray")
plotYears(tipico_initial_yearly_analysis,tipico_final_yearly_analysis,0.5,0.55)
plotSeries(tipico_initial_yearly_analysis,tipico_final_yearly_analysis,0.5,0.55)
```

Tipico's change over time also shows no significant improvements.

Let's try for another probability range

```{r}
par(bg="gray")
plotYears(tipico_initial_yearly_analysis,tipico_final_yearly_analysis,0.4,0.45)
plotSeries(tipico_initial_yearly_analysis,tipico_final_yearly_analysis,0.4,0.45)
```

The changes seem to be very random in this range as well.

## 3.6 Analysis of Interwetten
### 3.6.1 Task 1.a

```{r}
interwetten_initial <- initial_merged_data[bookmaker == "Interwetten"]
interwetten_final <- final_merged_data[bookmaker == "Interwetten"]


interwetten_initial_summary=interwetten_initial[,list(empirical_over=mean(IsOver),
                                            probabilistic_over=mean(probOver),.N),
                                      by=list(odd_cut_over)]


interwetten_final_summary=interwetten_final[,list(empirical_over=mean(IsOver),
                                        probabilistic_over=mean(probOver),.N),
                                  by=list(odd_cut_over)]

par(bg="gray")
plot(interwetten_initial_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "blue", pch = 2, xlab = "Empirical Over", ylab = "Probabilistic Over", main = "Comparison of Initial and Final Probabilities")
points(interwetten_final_summary[,list(empirical_over,probabilistic_over)],cex=2, col = "red", pch = 5)
abline(0,1,col='green')
```

The points in this graph is also close to the line. But, there are less points, and they are not as close as the other bookmakers. Again, there is no significant relationship between initial and final odds.

### 3.6.2 Task 1.b

```{r}
interwetten_final_yearly_analysis=interwetten_final[,list(empirical_over=mean(IsOver),
                                                probabilistic_over=mean(probOver),.N),
                                          by=list(Year,odd_cut_over)]

interwetten_final_yearly_analysis=interwetten_final_yearly_analysis[order(Year)]


interwetten_initial_yearly_analysis=interwetten_initial[,list(empirical_over=mean(IsOver),
                                                    probabilistic_over=mean(probOver),.N),
                                              by=list(Year,odd_cut_over)]

interwetten_initial_yearly_analysis=interwetten_initial_yearly_analysis[order(Year)]

par(bg="gray")
plotYears(interwetten_initial_yearly_analysis,interwetten_final_yearly_analysis,0.5,0.55)
plotSeries(interwetten_initial_yearly_analysis,interwetten_final_yearly_analysis,0.5,0.55)
```

There are random changes among years. No significant improvements occur over time.


# 4. Task 2

## 4.1 Number of Changes
In this task, we are asked to analyze the change in the odds. I will firstly prepare the data.

```{r}
odds_1x2 <- odds[odds$betType == "1x2",]
odds_1x2[,totalhandicap:=NULL]
odds_1x2 <- odds_1x2[complete.cases(odds_1x2)]

odds_1x2=odds_1x2[order(matchId, oddtype,bookmaker,date)]

odds_1x2_initial=odds_1x2[,list(start_odd=odd[1]),
                              by=list(matchId,oddtype,bookmaker)]

odds_1x2_final=odds_1x2[,list(final_odd=odd[.N]),
                            by=list(matchId,oddtype,bookmaker)]
odds1 <- odds_1x2[oddtype == "odd1"]
```

I will firstly observe the number of changes per match. First see how the changes are distributed.

```{r}
number_of_changes <- odds1[,list(changeNum = length(odd)), by = list(matchId, oddtype, bookmaker)]
number_of_changes <- merge(number_of_changes, matches[,c("matchId", "Year")], by = "matchId")
number_of_changes <- number_of_changes[complete.cases(number_of_changes)]
par(bg="gray")
hist(number_of_changes$changeNum, xlab = "Number of Changes", main = "Histogram of Number of Changes")
```

As expected, the frequency of the number of changes decreases as the number increases. Now, let's take a look at the details.

```{r}
summary(number_of_changes)
```

The mean number of changes is 6.806, while the median is 2. They seem to be very low, however, there are some large changes as well. Now, let's explore is there a relationship between time and number of changes.


## 4.2 Mean Changes over Time
```{r}
mean_changes <- number_of_changes[,list(mean=mean(changeNum)), by=list(Year)]
mean_changes <- mean_changes[order(Year)]
par(bg="gray")
plot(mean_changes, type = "o", col = "blue", ylab = "Mean Changes", main = "Average Number of Changes per Match over Time")

```

A significant evidence exists in the graph. As we can observe, the mean number of changes per match seems to be constant between 2010 and 2016. However, after 2016, the number explodes. This may relate to a change in the technology of changing odds, as well as a change in the regulations on betting systems.

## 4.3 Changes in the Distributions

In this part, we will explore if there is any significant changes in the distributions between initial and final odds.

Firstly, we need to prepare the data. The preparation process is included in the Appendix for the sake of simplicity
```{r, include=FALSE,eval=TRUE}
###wide all data
#generate probabilities for 1x2 odds
wide_initial_1x2 <- dcast(odds_1x2_initial,
                           matchId + bookmaker ~oddtype,
                           value.var="start_odd")

wide_initial_1x2[,prob1 := 1/odd1]
wide_initial_1x2[,prob2 := 1/odd2]
wide_initial_1x2[,probx := 1/oddX]
wide_initial_1x2[,totalprob := prob1 + prob2 + probx]
wide_initial_1x2[,prob1 := prob1/totalprob]
wide_initial_1x2[,prob2 := prob2/totalprob]
wide_initial_1x2[,probx := probx/totalprob]
wide_initial_1x2[,totalprob := NULL]
wide_initial_1x2 <- wide_initial_1x2[complete.cases(wide_initial_1x2)]
wide_initial_1x2[,prob1_cut:=cut(prob1,cutpoints)]
wide_initial_1x2[,prob2_cut:=cut(prob2,cutpoints)]
wide_initial_1x2[,probx_cut:=cut(probx,cutpoints)]
wide_initial_1x2 <- merge(wide_initial_1x2,matches[,c("matchId", "Is1","Is2","IsX")],by='matchId')

#same thing for final data
wide_final_1x2 <- dcast(odds_1x2_final,
      matchId + bookmaker ~oddtype,
      value.var="final_odd")

wide_final_1x2[,prob1 := 1/odd1]
wide_final_1x2[,prob2 := 1/odd2]
wide_final_1x2[,probx := 1/oddX]
wide_final_1x2[,totalprob := prob1 + prob2 + probx]
wide_final_1x2[,prob1 := prob1/totalprob]
wide_final_1x2[,prob2 := prob2/totalprob]
wide_final_1x2[,probx := probx/totalprob]
wide_final_1x2[,totalprob := NULL]
wide_final_1x2 <- wide_final_1x2[complete.cases(wide_final_1x2)]
wide_final_1x2[,prob1_cut:=cut(prob1,cutpoints)]
wide_final_1x2[,prob2_cut:=cut(prob2,cutpoints)]
wide_final_1x2[,probx_cut:=cut(probx,cutpoints)]
wide_final_1x2 <- merge(wide_final_1x2,matches[,c("matchId", "Is1","Is2","IsX")],by='matchId')


#histograms are saved as seperate objects
initial_prob1_hist <- hist(wide_initial_1x2$prob1)
initial_prob2_hist <- hist(wide_initial_1x2$prob2)
initial_probx_hist <- hist(wide_initial_1x2$probx)

final_prob1_hist <- hist(wide_final_1x2$prob1)
final_prob2_hist <- hist(wide_final_1x2$prob2)
final_probx_hist <- hist(wide_final_1x2$probx)
```
Now, we can create histograms. 
```{r}
plot(initial_prob1_hist, col = rgb(1,0,0,1/4), xlim = c(0,1), xlab =  "Probability", main = "Initial and Final 1 Distributions")
plot(final_prob1_hist, col = rgb(0,0,1,1/4), xlim = c(0,1), add = TRUE)
lines(initial_prob1_hist$mids, initial_prob1_hist$counts,  col = "red", type = "o")
lines(final_prob1_hist$mids, final_prob1_hist$counts, col = "blue", type = "o")
```

Red and blue lines shows the initial and final distributions for odd1. Odd1 seems to be similar to normal distribution.

```{r}
plot(initial_prob2_hist, col = rgb(1,0,0,1/4), xlim = c(0,1), xlab =  "Probability", main = "Initial and Final 2 Distributions")
plot(final_prob2_hist, col = rgb(0,0,1,1/4), xlim = c(0,1), add = TRUE)
lines(initial_prob2_hist$mids, initial_prob2_hist$counts,  col = "red", type = "o")
lines(final_prob2_hist$mids, final_prob2_hist$counts, col = "blue", type = "o")
```

Odd2 distribution is different than Odd1. It seems to winning probability of away team gets very low after 0.3. There is no signigicant difference between initial and final distributions.



```{r}
plot(initial_probx_hist, col = rgb(1,0,0,1/4), xlim = c(0,1), xlab =  "Probability", main = "Initial and Final X Distributions")
plot(final_probx_hist, col = rgb(0,0,1,1/4), xlim = c(0,1), add = TRUE)
lines(initial_probx_hist$mids, initial_probx_hist$counts,  col = "red", type = "o")
lines(final_probx_hist$mids, final_probx_hist$counts, col = "blue", type = "o")
```

For OddX, the distribution sharply decreases after 0.3 which may be concluded as bookmakers has very little evidence for determining oddX.



# 5 Conclusion

For the first part, we can conclude that all of the 5 bookmakers are very good at determining their odds. Their average probabilites and empirical probabilities are very close to each other. Additionally, there is no significant relationships observed between initial and final odds. Even some initial odds perform better than final ones. Finally, the changes over time seems to be random. There are no significant improvements over time in all of the bookmakers in the observed probability ranges.

In the second parts, the results show that the number of changes per match is very low in general. However, the changes seems to increase in the last 2 years exponentially. Another result is there is no significant change in the distribution of initial and final probabilities.


# 6 Appendix
## 6.1 Part 4.3 Data Preparation
```{r, include=TRUE,eval=TRUE}
###wide all data
#generate probabilities for 1x2 odds
wide_initial_1x2 <- dcast(odds_1x2_initial,
                           matchId + bookmaker ~oddtype,
                           value.var="start_odd")

wide_initial_1x2[,prob1 := 1/odd1]
wide_initial_1x2[,prob2 := 1/odd2]
wide_initial_1x2[,probx := 1/oddX]
wide_initial_1x2[,totalprob := prob1 + prob2 + probx]
wide_initial_1x2[,prob1 := prob1/totalprob]
wide_initial_1x2[,prob2 := prob2/totalprob]
wide_initial_1x2[,probx := probx/totalprob]
wide_initial_1x2[,totalprob := NULL]
wide_initial_1x2 <- wide_initial_1x2[complete.cases(wide_initial_1x2)]
wide_initial_1x2[,prob1_cut:=cut(prob1,cutpoints)]
wide_initial_1x2[,prob2_cut:=cut(prob2,cutpoints)]
wide_initial_1x2[,probx_cut:=cut(probx,cutpoints)]
wide_initial_1x2 <- merge(wide_initial_1x2,matches[,c("matchId", "Is1","Is2","IsX")],by='matchId')

#same thing for final data
wide_final_1x2 <- dcast(odds_1x2_final,
      matchId + bookmaker ~oddtype,
      value.var="final_odd")

wide_final_1x2[,prob1 := 1/odd1]
wide_final_1x2[,prob2 := 1/odd2]
wide_final_1x2[,probx := 1/oddX]
wide_final_1x2[,totalprob := prob1 + prob2 + probx]
wide_final_1x2[,prob1 := prob1/totalprob]
wide_final_1x2[,prob2 := prob2/totalprob]
wide_final_1x2[,probx := probx/totalprob]
wide_final_1x2[,totalprob := NULL]
wide_final_1x2 <- wide_final_1x2[complete.cases(wide_final_1x2)]
wide_final_1x2[,prob1_cut:=cut(prob1,cutpoints)]
wide_final_1x2[,prob2_cut:=cut(prob2,cutpoints)]
wide_final_1x2[,probx_cut:=cut(probx,cutpoints)]
wide_final_1x2 <- merge(wide_final_1x2,matches[,c("matchId", "Is1","Is2","IsX")],by='matchId')


#histograms are saved as seperate objects
initial_prob1_hist <- hist(wide_initial_1x2$prob1)
initial_prob2_hist <- hist(wide_initial_1x2$prob2)
initial_probx_hist <- hist(wide_initial_1x2$probx)

final_prob1_hist <- hist(wide_final_1x2$prob1)
final_prob2_hist <- hist(wide_final_1x2$prob2)
final_probx_hist <- hist(wide_final_1x2$probx)
```

